{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"reference\n1. https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md\n2. https://www.kaggle.com/khanhlvg/cots-detection-w-tensorflow-object-detection-api/notebook#Import-dependencies","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/tensorflow/models\n    \n# Check out a certain commit to ensure that future changes in the TF ODT API codebase won't affect this notebook.\n!cd models && git checkout ac8d06519","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T13:09:00.345875Z","iopub.execute_input":"2022-01-10T13:09:00.346233Z","iopub.status.idle":"2022-01-10T13:09:44.138316Z","shell.execute_reply.started":"2022-01-10T13:09:00.346141Z","shell.execute_reply":"2022-01-10T13:09:44.137126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\ncd models/research\n\n# Compile protos.\nprotoc object_detection/protos/*.proto --python_out=.\n\n# Install TensorFlow Object Detection API.\n# Note: I fixed the version of some dependencies to make it work on Kaggle notebook. In particular:\n# * scipy==1.6.3 to avoid the missing GLIBCXX_3.4.26 error\n# * tensorflow to 2.6.0 to make it compatible with the CUDA version preinstalled on Kaggle.\n# When Kaggle notebook upgrade to TF 2.7, you can use the default setup.py script:\n# cp object_detection/packages/tf2/setup.py .\nwget https://storage.googleapis.com/odml-dataset/others/setup.py\npip install -q --user .\n\n# Test if the Object Dectection API is working correctly\npython object_detection/builders/model_builder_tf2_test.py","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:09:44.140659Z","iopub.execute_input":"2022-01-10T13:09:44.140992Z","iopub.status.idle":"2022-01-10T13:12:45.681429Z","shell.execute_reply.started":"2022-01-10T13:09:44.140952Z","shell.execute_reply":"2022-01-10T13:12:45.679196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Revert some changes in the pyparsing library - fingers crossed\nwith open(\"/root/.local/lib/python3.7/site-packages/httplib2/auth.py\", 'r') as f:\n    text = f.read()\n\ntext = text.replace(\"pp.downcaseTokens\", \"pp.pyparsing_common.downcase_tokens\")\n\nwith open(\"/root/.local/lib/python3.7/site-packages/httplib2/auth.py\", 'w') as f:\n    f.write(text)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:45.68691Z","iopub.execute_input":"2022-01-10T13:12:45.687459Z","iopub.status.idle":"2022-01-10T13:12:45.699621Z","shell.execute_reply.started":"2022-01-10T13:12:45.687403Z","shell.execute_reply":"2022-01-10T13:12:45.698307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import contextlib2\nimport io\nimport IPython\nimport json\nimport numpy as np\nimport os\nimport pathlib\nimport pandas as pd\nimport sys\nimport tensorflow as tf\nimport time\n\nfrom PIL import Image, ImageDraw\n\n# Import the library that is used to submit the prediction result.\nINPUT_DIR = '/kaggle/input/tensorflow-great-barrier-reef/'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:45.702674Z","iopub.execute_input":"2022-01-10T13:12:45.70296Z","iopub.status.idle":"2022-01-10T13:12:47.897935Z","shell.execute_reply.started":"2022-01-10T13:12:45.702926Z","shell.execute_reply":"2022-01-10T13:12:47.896774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The notebook is supposed to run with TF 2.6.0\nprint(tf.__version__)\nprint(tf.test.is_gpu_available())\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:47.899638Z","iopub.execute_input":"2022-01-10T13:12:47.899857Z","iopub.status.idle":"2022-01-10T13:12:47.908906Z","shell.execute_reply.started":"2022-01-10T13:12:47.899829Z","shell.execute_reply":"2022-01-10T13:12:47.908212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from object_detection.utils import dataset_util\nfrom object_detection.dataset_tools import tf_record_creation_util","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:47.910271Z","iopub.execute_input":"2022-01-10T13:12:47.910544Z","iopub.status.idle":"2022-01-10T13:12:48.151901Z","shell.execute_reply.started":"2022-01-10T13:12:47.910498Z","shell.execute_reply":"2022-01-10T13:12:48.150641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    full_df_fp = \"../input/cots-train-test-split/train_df.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:48.153377Z","iopub.execute_input":"2022-01-10T13:12:48.154305Z","iopub.status.idle":"2022-01-10T13:12:48.160092Z","shell.execute_reply.started":"2022-01-10T13:12:48.154241Z","shell.execute_reply":"2022-01-10T13:12:48.158767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_df = pd.read_csv(CONFIG.full_df_fp, index_col=0)\nfull_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:48.162071Z","iopub.execute_input":"2022-01-10T13:12:48.163045Z","iopub.status.idle":"2022-01-10T13:12:48.359268Z","shell.execute_reply.started":"2022-01-10T13:12:48.162991Z","shell.execute_reply":"2022-01-10T13:12:48.35822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df = full_df[full_df['k_fold']==0]\ntrain_df = full_df[full_df['k_fold']!=0]\nprint(\"Validation df size: \", len(valid_df))\nprint(\"Training df size: \", len(train_df))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T13:12:48.360762Z","iopub.execute_input":"2022-01-10T13:12:48.361016Z","iopub.status.idle":"2022-01-10T13:12:48.374524Z","shell.execute_reply.started":"2022-01-10T13:12:48.360986Z","shell.execute_reply":"2022-01-10T13:12:48.373553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating TF records\nFollowing the official documentation, we will need to create examples based on the following format. Then use TF writer to write the examples into TFRecords. Based on previous experience, we will need to have a reasonable number of TFRecords in order to train on TPU eg > 16 in multiples of 8\n\n\nFor each example, we will need the following\\\n'image/height': dataset_util.int64_feature(height),\\\n'image/width': dataset_util.int64_feature(width),\\\n'image/filename': dataset_util.bytes_feature(filename),\\\n'image/source_id': dataset_util.bytes_feature(filename),\\\n'image/encoded': dataset_util.bytes_feature(encoded_jpg),\\\n'image/format': dataset_util.bytes_feature(image_format),\\\n'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\\\n'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\\\n'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\\\n'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\\\n'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\\\n'image/object/class/label': dataset_util.int64_list_feature(classes)","metadata":{}},{"cell_type":"code","source":"def create_tf_example(video_id, video_frame, annotations, image_path):\n    '''Create  a single tf example'''\n    with tf.io.gfile.GFile(image_path ,'rb') as bfile:\n        encoded_img = bfile.read()\n        \n    #reduce reading from disk\n    encoded_jpg_io = io.BytesIO(encoded_img)\n    \n    pil_image = Image.open(encoded_jpg_io)\n    height = pil_image.height\n    width = pil_image.width\n    filename = f\"{video_id}:{video_frame}\".encode('utf8')\n    image_format='jpeg'.encode('utf8')\n    \n    annotations = json.loads(annotations.replace(\"'\", '\"'))\n    \n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    texts = []\n    labels = []\n    \n    for annotation in annotations:\n        xmins.append(annotation['x']/ width)\n        xmaxs.append((annotation['x']+annotation['width'])/width) # normailzed x \n        ymins.append(annotation['y']/height)\n        ymaxs.append((annotation['y']+annotation['height'])/height) #normalized y\n        texts.append(\"COTS\".encode('utf8'))\n        labels.append(1)\n    \n    # 1 tf example will contain 1 image\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height), #type tf.train.Feature\n        'image/width' : dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(encoded_img),\n        'image/format' : dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(texts),\n        'image/object/class/label': dataset_util.int64_list_feature(labels)\n        \n    }))\n    \n    return tf_example\n    \ndef convert_to_tfrecord(data_df, tfrecord_filebase, num_shards):\n    with contextlib2.ExitStack() as tf_record_close_stack:\n        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(tf_record_close_stack,\n                                                                                 tfrecord_filebase,\n                                                                                 num_shards)\n        for index, row in data_df.iterrows():\n            if (index+1) % 500 == 0:\n                print(f\"Processed {index} images\")\n            \n            tf_example = create_tf_example(row['video_id'], row['video_frame'],\n                                           row['annotations'] ,row['filepath'] )\n            \n            output_shard_index = index % num_shards\n            output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n            \n        print('Completed processing {0} images.'.format(len(data_df)))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:10:37.082655Z","iopub.execute_input":"2022-01-10T14:10:37.08295Z","iopub.status.idle":"2022-01-10T14:10:37.099448Z","shell.execute_reply.started":"2022-01-10T14:10:37.082917Z","shell.execute_reply":"2022-01-10T14:10:37.098779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"dataset\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:10:39.509171Z","iopub.execute_input":"2022-01-10T14:10:39.510172Z","iopub.status.idle":"2022-01-10T14:10:39.514194Z","shell.execute_reply.started":"2022-01-10T14:10:39.510128Z","shell.execute_reply":"2022-01-10T14:10:39.513559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating TFRecords","metadata":{}},{"cell_type":"code","source":"print('Converting TRAIN images...')\nconvert_to_tfrecord(\n  train_df,\n  'dataset/cots_train',\n  num_shards = 32)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:10:40.791139Z","iopub.execute_input":"2022-01-10T14:10:40.791805Z","iopub.status.idle":"2022-01-10T14:14:18.498631Z","shell.execute_reply.started":"2022-01-10T14:10:40.791762Z","shell.execute_reply":"2022-01-10T14:14:18.497762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Converting validation images...')\nconvert_to_tfrecord(\n  valid_df,\n  'dataset/cots_valid',\n  num_shards = 8\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:14:18.500374Z","iopub.execute_input":"2022-01-10T14:14:18.500779Z","iopub.status.idle":"2022-01-10T14:15:09.765918Z","shell.execute_reply.started":"2022-01-10T14:14:18.500745Z","shell.execute_reply":"2022-01-10T14:15:09.764597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabel_map_str = \"\"\"item {\n  id: 1\n  name: 'COTS'\n}\"\"\"\n\nwith open('dataset/label_map.pbtxt', 'w') as f:\n    f.write(label_map_str)\n\n!more dataset/label_map.pbtxt","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:17:02.143439Z","iopub.execute_input":"2022-01-10T14:17:02.143946Z","iopub.status.idle":"2022-01-10T14:17:02.989129Z","shell.execute_reply.started":"2022-01-10T14:17:02.1439Z","shell.execute_reply":"2022-01-10T14:17:02.987946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Zipping the TFRecords","metadata":{}},{"cell_type":"code","source":"!zip -r COTS_tfrecords.zip ./dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-10T14:19:21.195083Z","iopub.execute_input":"2022-01-10T14:19:21.195497Z","iopub.status.idle":"2022-01-10T14:23:13.273039Z","shell.execute_reply.started":"2022-01-10T14:19:21.19544Z","shell.execute_reply":"2022-01-10T14:23:13.271958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}