{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## In this notebook, we will explore the dataset and convert the data into the input format required by tensorflow object detection API\n\nReferences\n1. https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md\n2. https://www.kaggle.com/khanhlvg/cots-detection-w-tensorflow-object-detection-api#Prepare-the-training-dataset","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn==1.0.2  we dont need this","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:48:09.118989Z","iopub.execute_input":"2022-01-09T13:48:09.119281Z","iopub.status.idle":"2022-01-09T13:48:27.769579Z","shell.execute_reply.started":"2022-01-09T13:48:09.119253Z","shell.execute_reply":"2022-01-09T13:48:27.768417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom ast import literal_eval\nfrom PIL import Image, ImageDraw\nfrom IPython import display\nfrom tqdm.notebook import tqdm\nimport os\n\nfrom sklearn.model_selection import StratifiedGroupKFold \n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T13:49:52.690908Z","iopub.execute_input":"2022-01-09T13:49:52.691707Z","iopub.status.idle":"2022-01-09T13:49:52.697216Z","shell.execute_reply.started":"2022-01-09T13:49:52.691663Z","shell.execute_reply":"2022-01-09T13:49:52.696489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    train_images_root_dir = \"../input/tensorflow-great-barrier-reef/train_images\"\n    train_meta_data_dir = \"../input/tensorflow-great-barrier-reef/train.csv\"\n    n_splits = 5","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:37:44.1767Z","iopub.execute_input":"2022-01-09T12:37:44.177228Z","iopub.status.idle":"2022-01-09T12:37:44.182219Z","shell.execute_reply.started":"2022-01-09T12:37:44.177158Z","shell.execute_reply":"2022-01-09T12:37:44.181309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(CONFIG.train_meta_data_dir)\ntrain_df['annotations'] = train_df['annotations'].map(lambda x:literal_eval(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:01.757686Z","iopub.execute_input":"2022-01-09T12:35:01.757972Z","iopub.status.idle":"2022-01-09T12:35:02.186238Z","shell.execute_reply.started":"2022-01-09T12:35:01.75794Z","shell.execute_reply":"2022-01-09T12:35:02.185641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the % of frames where n starfish are detected","metadata":{}},{"cell_type":"code","source":"train_df['n_cots_det'] = train_df['annotations'].map(lambda x: len(x))\ntrain_df.iloc[20:25]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:02.424101Z","iopub.execute_input":"2022-01-09T12:35:02.424644Z","iopub.status.idle":"2022-01-09T12:35:02.45315Z","shell.execute_reply.started":"2022-01-09T12:35:02.424593Z","shell.execute_reply":"2022-01-09T12:35:02.452227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that there are some frames with alot of detections\nlets check if they are valid","metadata":{}},{"cell_type":"code","source":"train_df['n_cots_det'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:02.940285Z","iopub.execute_input":"2022-01-09T12:35:02.940656Z","iopub.status.idle":"2022-01-09T12:35:02.95473Z","shell.execute_reply.started":"2022-01-09T12:35:02.940612Z","shell.execute_reply":"2022-01-09T12:35:02.953611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the filepaths for the dataset","metadata":{}},{"cell_type":"code","source":"def get_file_paths(dataframe):\n    dataframe = dataframe.copy()\n    df_length = len(dataframe)\n    \n    filepaths = []\n    \n    for i in tqdm(range(df_length)):\n        row = dataframe.iloc[i]\n        video_folder = f\"video_{row['video_id']}\"\n        image_name = f\"{row['video_frame']}.jpg\"\n        filepath = os.path.join(CONFIG.train_images_root_dir, video_folder, image_name)\n        filepaths.append(filepath)\n    \n    dataframe['filepath'] = filepaths\n    return dataframe\n\ntrain_df = get_file_paths(train_df)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:03.352345Z","iopub.execute_input":"2022-01-09T12:35:03.352896Z","iopub.status.idle":"2022-01-09T12:35:06.724578Z","shell.execute_reply.started":"2022-01-09T12:35:03.352848Z","shell.execute_reply":"2022-01-09T12:35:06.72361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing some of the training data\n","metadata":{}},{"cell_type":"code","source":"def plot_image_with_bbox(image_filepath, annotations):\n    image = Image.open(image_filepath)\n    draw = ImageDraw.Draw(image) # returns a ImageDraw object\n    \n    for annotation in annotations:\n        draw.rectangle([\n            annotation['x'], annotation['y'], \n            annotation['x']+annotation['width'], annotation['y']+annotation['height']\n        ], outline='red', width=3)\n    plt.figure(figsize=(20,20))    \n    plt.imshow(image)\n\ndef plot_batch_image_with_bbox(subset_df, max_plots=10):\n    length = len(subset_df)\n#     sample_size = min(length, max_plots)\n#     subset_df = subset_df.sample(sample_size).copy()\n    subset_df.reset_index(inplace=True, drop=True)\n    \n    \n    for i in range(length):\n        row=subset_df.iloc[i]\n        plot_image_with_bbox(row[\"filepath\"], row['annotations'])\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:06.726333Z","iopub.execute_input":"2022-01-09T12:35:06.726605Z","iopub.status.idle":"2022-01-09T12:35:06.734134Z","shell.execute_reply.started":"2022-01-09T12:35:06.726561Z","shell.execute_reply":"2022-01-09T12:35:06.733234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_batch_image_with_bbox(train_df[train_df['n_cots_det']==18])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:06.735472Z","iopub.execute_input":"2022-01-09T12:35:06.735724Z","iopub.status.idle":"2022-01-09T12:35:09.817731Z","shell.execute_reply.started":"2022-01-09T12:35:06.735662Z","shell.execute_reply":"2022-01-09T12:35:09.815408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train validation split\nFor this 3 videos, its important to split the data into train validation properly as subsequent frames are very similar so we cannot randomly split them or it will cause serious data leak. Some option will be as follows. We can also see that around 22% of the images contains COTS so we will also need to split them in approximate ratio to reflex the \"true\" distribution\n\n1. If we training by video and essemble them, but it might take too long for inference\n2. Group the data into fixed window size to minimize the subsequent frame in the validation data\n3. Split the data into groups seperated by zero detection and use StratifiedGroupKfold\n","metadata":{}},{"cell_type":"code","source":"train_df['is_cot_detected'] = (train_df['n_cots_det']>0).astype(np.int32)\ntrain_df['is_cot_detected'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:35:09.819665Z","iopub.execute_input":"2022-01-09T12:35:09.819921Z","iopub.status.idle":"2022-01-09T12:35:10.053759Z","shell.execute_reply.started":"2022-01-09T12:35:09.819889Z","shell.execute_reply":"2022-01-09T12:35:10.053077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assign_group(is_detected_list:list)->list: \n    groupings = [0]\n    n_samples = len(is_detected_list)\n    group_num = 0\n    length_counter = 0\n    for i in range(1, n_samples):\n        if is_detected_list[i] == 0 and is_detected_list[i-1] == 1:\n            # start of new group \n            group_num += 1\n            length_counter = 0\n            groupings.append(group_num)\n        \n        elif length_counter == 2000 and is_detected_list[i-1] == 0:\n            group_num += 1\n            length_counter = 0\n            groupings.append(group_num)\n            \n        else:\n            groupings.append(group_num)\n            length_counter +=1\n            \n    return groupings\n   ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:52:32.709021Z","iopub.execute_input":"2022-01-09T12:52:32.709839Z","iopub.status.idle":"2022-01-09T12:52:32.71662Z","shell.execute_reply.started":"2022-01-09T12:52:32.709792Z","shell.execute_reply":"2022-01-09T12:52:32.715676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['group_number'] = assign_group(train_df['is_cot_detected'].tolist())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:52:33.57872Z","iopub.execute_input":"2022-01-09T12:52:33.579133Z","iopub.status.idle":"2022-01-09T12:52:33.603522Z","shell.execute_reply.started":"2022-01-09T12:52:33.579101Z","shell.execute_reply":"2022-01-09T12:52:33.602793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['group_number']","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:52:46.238798Z","iopub.execute_input":"2022-01-09T12:52:46.23906Z","iopub.status.idle":"2022-01-09T12:52:46.245823Z","shell.execute_reply.started":"2022-01-09T12:52:46.239032Z","shell.execute_reply":"2022-01-09T12:52:46.244912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_fold_spilter = StratifiedGroupKFold(n_splits=CONFIG.n_splits)\nk_fold_n = 0\nfor train_idx, test_idx in k_fold_spilter.split(train_df['is_cot_detected'],train_df['is_cot_detected'], groups=train_df['group_number']):\n    train_df.iloc[test_idx,-1] = k_fold_n\n    k_fold_n+=1","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:52:50.636634Z","iopub.execute_input":"2022-01-09T12:52:50.637157Z","iopub.status.idle":"2022-01-09T12:52:50.715761Z","shell.execute_reply.started":"2022-01-09T12:52:50.637118Z","shell.execute_reply":"2022-01-09T12:52:50.715176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:52:51.658893Z","iopub.execute_input":"2022-01-09T12:52:51.659362Z","iopub.status.idle":"2022-01-09T12:52:51.680244Z","shell.execute_reply.started":"2022-01-09T12:52:51.659315Z","shell.execute_reply":"2022-01-09T12:52:51.679572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    subset = train_df[train_df['k_fold']==i].copy()\n    print(f\"Fold {i} length: \", len(subset))\n    print(f\"Fold {i} cot det\", subset['is_cot_detected'].sum())\n    print(f\"Fold {i} cot det percentage\", subset['is_cot_detected'].sum()/len(subset))\n    print(\"Groups\")\n    print(subset['group_number'].unique())\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:54:37.156489Z","iopub.execute_input":"2022-01-09T12:54:37.156774Z","iopub.status.idle":"2022-01-09T12:54:37.180304Z","shell.execute_reply.started":"2022-01-09T12:54:37.156742Z","shell.execute_reply":"2022-01-09T12:54:37.179438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"train_df.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:55:16.738201Z","iopub.execute_input":"2022-01-09T12:55:16.738488Z","iopub.status.idle":"2022-01-09T12:55:16.872985Z","shell.execute_reply.started":"2022-01-09T12:55:16.738459Z","shell.execute_reply":"2022-01-09T12:55:16.872087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}